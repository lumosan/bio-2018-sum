%!TEX root = report.tex
\documentclass[a4paper]{article}
\input{_core.tex}

\usepackage{parskip}

\addbibresource{mybib.bib}

% Global variables
  \newcommand{\HWTitle}{Biometrics}
  \newcommand{\HWSubtitle}{Summary}
  \newcommand{\HWDueDate}{\today}
  \newcommand{\HWAuthorName}{Luc√≠a Montero Sanchis}
  \title{\vspace{-.25cm} \HWTitle \\ \vspace{.25cm}}
  %\date{\HWDueDate}
  \author{\HWAuthorName}

\begin{document}
\maketitle

\section*{Question 1 -- Leading Biometric Technology} % (fold)
\label{sec:question_1}
  \subsection*{Physiological Characteristics}
    \subsubsection*{01. Fingerprint}
      \begin{figure}[htp]
        \centering
          \includegraphics[width=.7\textwidth]{summaries/finger.png}
          %\caption{Sample Figure}
          %\label{fig:sample fig}
      \end{figure}
      \begin{figure}[htp]
        \centering
          \includegraphics[width=.7\textwidth]{summaries/finger2.png}
          %\caption{Sample Figure}
          %\label{fig:sample fig}
      \end{figure}
      \newpage
      \textbf{Generalities}:
      \begin{itemize}
        \item Friction skin (hairless, many sweat glands...). \emph{Biological} (physiological) characteristic. \emph{Applications} in security and forensics. \emph{Characteristics}: permanent (except for desease, scarring...), unique (even with same DNA).
        \item \emph{Galton's details} -- It suffices if 12 points are the same between two fingerprints.
        \item \textbf{Lights-out identification} -- system requiring minimal or zero human assistance that outputs a short candidate list.
        \item India Universal ID System with Biometrics -- \emph{To give the poor an identity}
        \item \textbf{Fake finger} (spoof attack) -- Gelatin, Silicone, Latex.
      \end{itemize}

      \textbf{Sensing}: Optical, capacitive, ultrasonic...
      \begin{itemize}
        \item \emph{On-line acquisition} -- Optical, Capacitive, Piezoelectric scanners. Single- or multi-finger
        \item \emph{Off-line acquisition} -- Thermal scanner, Inked impression, Latent fingerprint.
        \item Others: touchless (TBS The Surround Imager; Finger On The Fly), acquisition of derma image (internal fingerprint, more reliability).
      \end{itemize}

      \textbf{Feature extraction}: (level 1, 2 (minutiae) and 3 features)
      \begin{itemize}
        \item Minutiae: Ridge bifurcations, endings, ... (52 types)
        \item Core: Uppermost point on innermost ridge
        \item Delta: Separating point between pattern and non-pattern areas
        \item Pattern class: Determined by ridge flow characteristics.
        \item\textbf{Feature Levels}:
        \begin{itemize}
          \item \textbf{Level 1 -- singularities (core points)}: Core and delta points. Classification (left loop, right loop, whorl, arch, tented arch). Ridges (\emph{flow} can be described with \emph{directional map}; line density can be described with \emph{density map})
          \begin{itemize}
            \item \textbf{Average Square Gradient Method}: Gradient vector lengths are squared and their angles doubled.
            \item Noisy fingerprint $\rightarrow$ \emph{Local structure} for matching is very difficult, but \emph{global structure} is more stable.
          \end{itemize}
          \item \textbf{Level 2 -- Minutiae (major ridge path deviations)}: Ridge ending, Bifurcation, Valley, Lake, Independent Ridge, Point, Spur, Crossover.
          \item \textbf{Level 3 -- Intrinsic or innate ridge formations}: Sweat pores, incipient ridges, creases...
        \end{itemize}
      \end{itemize}

      \textbf{Templates}: (minutia coordinates and local ridge orientation, Delaunay triangulation and triangular matching)
      \begin{itemize}
        \item \textbf{Segmentation} (Isolate foreground from background)
        \item \textbf{Normalisation} (Mean 0 and variance 1, to standardise image intensity values)
        \item \textbf{Orientation image} (Computation of gradients over square-meshed grid)
        \item \textbf{Frequency image} (Ridge frequency)
        \item \textbf{Automatic Minutiae Detection}
        \begin{enumerate}
          \item Binarization
          \item Thinning
          \item Crossing number (Detection of minutiae)
        \end{enumerate}
        \item \textbf{Fingerprint enhancement -- Gabor filtering}: Contextual filters (characteristics change according to local context), context defined by local ridge orientation and frequency. Efficiently removes undesired noise preserving ridges and valleys.
        \item \textbf{Fourier Analysis} -- Interpreting the spectrum; alternate representation of the signal, providing more information. Filtering and convolution become trivial.
        \begin{itemize}
          \item Energy map
          \item Frequency map
          \item Orientation map
          \item Fourier Domain Based Enhancement
        \end{itemize}
        \item \textbf{Pre-alignment}:
        \begin{itemize}
          \item Absolute pre-alignment -- w.r.t. core and delta points. First align usign global structure, then use loca lstru  for point-to-point matching.
          \item Relative pre-alignment -- superimposing singularities, correlating orientation images, correlating ridge features.
        \end{itemize}
        \item \textbf{Match Score Generation}
        \item \textbf{Triangular matching} -- Delaunay triangulation creates a set of triangles such that triangles don't contain any other minutiae points.
      \end{itemize}

      \textbf{Matching (comparison)}:
      \begin{itemize}
        \item \textbf{Fingerprint Matching}:
        \begin{itemize}
          \item \emph{Correlation-based} -- Correlation between pixels computed for different alignments. Non-linear distortion and missalignments makes the correlation very difficult. Direct application of 2D correlation is very expensive computationally.
          \item \emph{Minutiae-based} -- Find the alignment that results in maximum number of minutiae pairings. Minutia Cylinder Code (MCC). Time consuming.
          \begin{itemize}
            \item MCC is computationally fast, easy bit-based implementation, invariant to rotation and translation.
          \end{itemize}
          \item \emph{Ridge feature-based} -- size and shape of fingerprint, number type and position of singularities, sweat pores, local orientation and frequency, ridge shape... FingerCode. \textbf{Gabor filter responses}.
          \begin{itemize}
            \item \emph{Texture-based Representation} -- Ridge pattern in fingerprint is seen as an oriented texture pattern with fixed dominant spatial frequency and orientation in a local neighborhood.
            \item \emph{Local texture patterns -- Local Binary Patterns LBPs}
          \end{itemize}
          \item \textbf{Hybrid}
        \end{itemize}
        \item \textbf{Intra-variability} -- Variations in impressions of one same finger. Overlap, displacement, rotation, non-linear distortion (because finger is 3D), pressure, skin condition, noise, \emph{feature extraction errors}.
        \begin{itemize}
          \item \emph{Feature extraction errors}: Aggresive enhancement, low-quality images...
        \end{itemize}
        \item \textbf{Local Clarity Score (LCS)} -- computes the block wise clarity of ridge and valleys by applying linear regression to determine a gray-level threshold, classifying pixels as ridge or valley.
        \begin{itemize}
          \item Minutiae + Local Correlation
          \item Minutiae + Local Binary Pattern (LBP) Histogram
        \end{itemize}
      \end{itemize}
      \newpage
    \subsubsection*{02. Face (2D and 3D)}
      \begin{figure}[htp]
        \centering
          \includegraphics[width=.7\textwidth]{summaries/face.png}
          %\caption{Sample Figure}
          %\label{fig:sample fig}
      \end{figure}
      \begin{figure}[htp]
        \centering
          \includegraphics[width=.7\textwidth]{summaries/face2.png}
          %\caption{Sample Figure}
          %\label{fig:sample fig}
      \end{figure}
      \textbf{Generalities}:
      \begin{itemize}
        \item Three levels of details:
        \begin{enumerate}
          \item General face geometry, global skin color -- <30 \emph{interpupilary distance} (IPD)
          \item Localized face information -- 30-75 IPD
          \item Unstructured micro level features: scars, freckles, moles, skin discoloration
        \end{enumerate}
        \item Complications: Facial expression, point of view, illumination, inter-class similarity, automatic face detection, appearance changes (quick, slow).
        \item Advantages: Low-cost, non-contact, non-intrusive, overt (user aware) or covert (user unaware), legacy databases, socially and culturally accepted, always acquires.
        \item Proprietary algorithms to generate templates $\rightarrow$ not-interoperable templates (interoperable \emph{original} photo). \emph{Receiving State} uses its own vendor algorithm to compare taken and stored facial images.
        \item \textbf{Machine Readable Travel Document} (\textbf{MRTD})
        \item ICAO standard: 300 dpi (112 kB); not cropped or cropped from chin to crown.
        \item Process:
        \begin{enumerate}
          \item Face Detection
          \item Face Normalization
          \item Feature Extraction
          \item Classification
        \end{enumerate}
      \end{itemize}

      \textbf{Sensing}:
      \begin{itemize}
        \item \textbf{Imaging challenges}:
        \begin{itemize}
          \item \textbf{Acquisition geometry} -- Necessary face detection; in-plane (1 degree of freedom) and in-depth (2 degrees of freedom) rotation; scale.
          \item \textbf{Imaging conditions} -- Lighting, intrinsic camera characteristics (automatic white balancing, gain control, noise reduction). \emph{Perfect conditions}: uniform background and lightning, acceptable quality.
          \item \textbf{Compression artifacts} -- Image degradations due to compression for transmission/storage. JPEG and MPEG often used but not designed to preserve human face.
        \end{itemize}
        \item \textbf{Detection} (what faces have in common, tell face from non-faces); \emph{Localization} (find position of one existing face); \textbf{Face recognition} (what differentiates two faces)
        \item Overlapped detections are merged if 60\% overlap.
        \item \emph{Detection} and \emph{Recognition} \textbf{approaches}:
        \begin{itemize}
          \item \textbf{Feature/Geometry-based} (analytic: eyes, mouth...) -- Matching feature constellations. \emph{Rotated models} (one model for each rotation).\\
          \textbf{Haar features}: \emph{Haar-like transform} calculates difference of intensity in neighbor regions. With low resolution images, better than purely geometrical methods. Applies Haar-like basis functions. \textbf{Viola-Jones} face detector.
          \item \textbf{Appearance-based} (local and global features, analyze distributions of individual faces in face space) -- Neural Networks, \textbf{PCA}, \textbf{LDA}, \textbf{HMM}, SVM, \textbf{GMM}, Graph matching.
        \end{itemize}
      \end{itemize}
        \begin{figure}[htp]
          \centering
            \includegraphics[width=\textwidth]{facesc.png}
            %\caption{Sample Figure}
            %\label{fig:sample fig}
        \end{figure}
      \textbf{Feature extraction}:
      \begin{itemize}
        \item \textbf{Appearance-based} Face Recognition:
          \begin{itemize}
            \item \emph{Local} Features (segment image and get several feature vectors):
              \begin{itemize}
                \item \textbf{2D-DCT} based (Discrete Cosine Transform): Divide in $m$ $u$ by $v$ blocks, obtain for each $n=uv$ DCT coefficients $\Rightarrow$ $m$ vectors of length $n$, each vector a row of matrix $M^{m,n}$.\\Coefficients are ordered in zig-zag pattern.\\
                Then \textbf{GMM}: 2D-DCT features for training; score = log-likelihood(2DDCT | model)
                \item Local Texture Patterns:
                \begin{itemize}
                  \item Local Binary Patterns \textbf{LBPs}:
                  $$\text{LPB}_{P,R}=\sum_{p=0}^{P-1}{s(g_p-g_c)2^p}$$
                  with $g_c$ the gray value of the center pixel $(x_c, y_c)$; $g_p$ the gray values of $P$ equally spaced pixels on a circle of radius $R$; $s$ a thresholding function s.t. $s=1$ if $x\geq 0$, else 0.\\
                  Histogram intersection measure: $H(p,q)=\frac{\sum_i{\min{(p_i, q_i)}}}{1/2\cdot(\sum_i{q_i}+\sum_i{p_i})}$
                  \item Local Ternary Patterns \textbf{LTPs}: One ternary code can be expressed as two binary codes (one is sustracted from the other). Ternary Codes use -1, 0 and 1 (instead of 1 and 0 only)
                \end{itemize}
              \end{itemize}
            \item \emph{Global} Features (Holistic approach, obtain one single feature vector):
              \begin{itemize}
                \item Principal Component Analysis \textbf{PCA}
                \item Linear Discriminant Analysis \textbf{LDA}
              \end{itemize}
            \item \textbf{2D Model: Elastic Bunch Graph Matching} (\emph{relational approach}, requires $\geq$ 2 images)
            \begin{itemize}
              \item Estimates a model of the relationship. Each face is represented by a set of feature vectors positioned on the nodes of a coarse \todo[inline]{what is coarse?} 2D grid.
              \item Each feature vector is a set of responses of 2D Gabor wavelets (different orientation and scale)
              \item \emph{Comparing faces}: By matching and adapting the grid of the test image to the grid of the reference. Both grids have same number of nodes
              \item Elasticity of grid allows for expression and view point changes adapting
              \item Quality of match evaluated with distance function
              \item Approach:
              \begin{enumerate}
                \item Split global transformation into set of local transformations
                \item Avoid over-flexibility
                \item Embed system with probabilistic framework of a 2D HMM
              \end{enumerate}
            \end{itemize}
            \item \textbf{3D Morphable Model} (\emph{Face-On-The-Fly})
            \begin{itemize}
              \item Based on surface matching. Pose-normalization required.
              \item Face geometry reconstructed in sub-millimeters (real ground-based measurement capturing x-y-z axes)
              \item Feature extraction based on underlying cranial structure (unique, permanent)
              \item Compact biometric template extracted. Possible RT face analysis, feature extraction and matching
              \item Robustness to changes in pose, lighting, makeup, and spoofing with photo.
              \item Face-On-The-Fly:
              \begin{enumerate}
                \item Face detection and tracking
                \item 3D pose and shape estimation
                \item Frontal view synthetis
                \item Matching algorithm
              \end{enumerate}
            \end{itemize}
          \end{itemize}
      \end{itemize}

      \textbf{Quality measures and Face Aging}:
      \begin{itemize}
        \item Quality of samples and metadata quality
        \item Illumination, brightness, contrast, focus, resolution, background, rotation, glasses...
        \item How to deal with \emph{age}: Performance improved by updating in time a decision threshold. Databases for investigation of age progression.
      \end{itemize}
      \newpage
    \subsubsection*{03. Iris}
      \begin{figure}[htp]
        \centering
          \includegraphics[width=.7\textwidth]{summaries/iris.png}
          %\caption{Sample Figure}
          %\label{fig:sample fig}
      \end{figure}
      \textbf{Generalities}:
      \begin{itemize}
        \item Biological. Distinctive features: arching ligaments, furrows, ridges, crypts, rings, corona, freckles, etc. Random pattern, mostly stable through life.
        \item \textbf{Epigenetic} (not genetically determined, as opposed to \emph{genotypic}).
        \item eBorders in the United Arab States.
        \item\textbf{Modules}:
        \begin{enumerate}
          \item \textbf{Acquisition} -- Get 2D image with \emph{monochromatic CCD camera} sensitive to \emph{NIR} (Near InfrarRed: 700-900 nm) light spectrum.\\
          Infrared light is preferred because it's more reflected by melanin than visible light, thus more iris texture is visible. Illumination is ANSI and Cenelec Certified safe to use. Pigmentation variations in iris are due to melanin density and are invisible in the NIR.
          \item \textbf{Segmentation} -- \emph{Localize iris} in eye image\\
          Edge Detection and Hough Transform -- The operator is a circular edge detector, can be used to detect the iris as well as the eyelid boundaries.
          \item \textbf{Normalization} -- Geometric normalization from \emph{Cartesian} to \emph{polar} coordinates $(r,\theta)$ with $r\in [0,1]$ and $\theta\in [0,2\pi]$\\
          This compensates pupil dilation and iris size inconsistencies but not rotational inconsistencies (this is accounted for during \emph{matching} by shifting the iris templates in the $\theta$ direction until templates are aligned)
          \item \textbf{Encoding} -- Feature extraction to produce a binary code. Invariant to pupil dilation and iris size. It's reliable and false. False Match Rate very small.\\
          2048 bits (256 bytes) are extracted from iris image and an equal number of masking bits to signify whether any region should be ignored in the demodulation code.\\
          The information extracted from the iris is described in terms of \emph{phase} $\Rightarrow$ \emph{insensitive} to contrast, camera gain, and illumination level (unlike correlation methods).\\
          Correlations within an iris (local structure is self-predicting). All IrisCode bits are equally likely to be 0 or 1 $\Rightarrow$ IrisCode  have \emph{maximum entropy} bitwise.
          \item \textbf{Comparison} -- How closely the produced code matches the encoded features in the database. Fractional Hamming Distance ($HD$, fraction of bits that disagree -- 10\% for same eye, 45\% for different)
            $$HD_\text{raw}=\frac{||(\text{code}_A \oplus\text{code}_B)\land \text{mask}_A\land \text{mask}_B||}{||\text{mask}_A\land \text{mask}_B||}$$
          \begin{itemize}
            \item Iris Code bit comparisons are Bernoulli Trials -- \emph{binomial distribution}:\\$f(x)=\frac{N!}{m!(N-m)!}p^m(1-p)^{N-m}$\\
            \item If \emph{less iris visible} then decision criterion becomes \emph{more demanding}:\\ $HD_\text{crit}=0.32-0.01\cdot\log_{10}{N}$
            \item Score re-normalisation to compensate for number of bits compared:\\$HD_\text{norm}=0.5-(0.5-HD_\text{raw})\sqrt{n/911}$
            \item Fewer (more) than 911 bits penalizes (improves) Hamming Distance. 1152 bits corresponds to 100\% visibility of each iris.
            \item Extremely fast when computed in parallel (1M IrisCodes per second with 3 Gb)
          \end{itemize}
        \end{enumerate}
      \end{itemize}

      \textbf{Sensing}:
      \begin{itemize}
        \item Techniques for improving user interface:
        \begin{itemize}
          \item Use extremely high resolution CCD \todo[inline]{que es CCD?}
          \item Well-designed optical system to improve DOF (Depth of Field)
          \item Cold mirror for user to adjust his eye
          \item Auto-focus
          \item Active pan/tilt camera optics
          \item Facial feature detection and tracking for guiding
          \item Distance sensor or image content based distance estimation
          \item Dual-eye iris camera
        \end{itemize}
      \end{itemize}

      \textbf{Matching (comparison)}:
      \begin{itemize}
        \item \textbf{Hamming Distance} -- Iris Codes are matched using a XOR to find bits at which they differ. AND is used to ensure that the compared bits are uncorrupted.
        \item \textbf{Liveness detection} -- Photonic and \emph{spectrographic} countermeasures (tissue, fat, blood and melanin pigment spectra; \emph{red eye} effect) and \emph{behavioral} countermeasures.
        \item \emph{Contact Lenses} and \emph{Large difference in dilation} result in few more False Rejections.
      \end{itemize}
      \newpage
    \subsubsection*{04. Periocular, Retina, Ear}
      \textbf{Generalities}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Sensing}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Feature extraction}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Templates}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Matching (comparison)}:
      \begin{itemize}
        \item 
      \end{itemize}
    \newpage
    \subsubsection*{05. Hand Geometry (shape)}
      \textbf{Generalities}:
      \begin{itemize}
        \item Biological (physiological). Typical visible images of the hand are (a) palmar, (b) lateral, (c) dorsal.
        \item Hand is unique: Finger length, width, thickness, curvatures and relative locations. Bone structure is constant after growth period.
        \item Only the silhouette of the hand is recorded. \emph{Orthographic scanning} (two distinct images, one from the top and one from the side)
        \item Inexpensive, robust to environmental changes, non-intrusive.
        \item Low accuracy, changes during childhood, difficult for some users (arthritis, missing fingers, large hands)
      \end{itemize}

      \textbf{Sensing}:
      \begin{table}[htp]
        \centering
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{lll}
          \toprule
          & \textbf{Pros} & \textbf{Cons}\\
          \midrule
          \textbf{Pegged} & Predefined axis to measure features & Pegs may deform shape\\
          \textbf{Non-Pegged} & More robust than Pegged to different placements & Difficult to locate axis to measure features\\
          \bottomrule
        \end{tabular}
        %\caption{Some table }
        %\label{tab:sample table}
      \end{table}
      \begin{itemize}
        \item \emph{Enrolment}: Two snapshots of the hand are taken and averaged
        \item \emph{Matching}: Newly sensed feature vector is compared (euclidean distance) with stored feature vector
        \item \textbf{Pegged} -- Feature extraction involves computing widths and lengths of fingers and palm at various locations (16 features)
        \item \textbf{Non-Pegged} -- Wrist reference, radial distance function (from wrist reference)
      \end{itemize}
    \subsubsection*{06. Palmprint and Palm Veins}
      \textbf{Palmprint}:
      \begin{itemize}
        \item \textbf{Sensing}
        \begin{itemize}
          \item Regions: interdigital, thenar and hypothenar
          \item Major creases: distal transverse crease (heart), proximal transverse crease (head), radial transverse crease (life)
          \item Palmprint: Ridges, minutiae and pores
          \item Preprocessing: Global thresholding; Contour-following algorithm; Reference points
        \end{itemize}
        \item \textbf{Region of Interest (ROI)} -- Subimages of regions of interest:  Little-finger, Ring-finger, Middle-finger, Index-finger, Thumb, Palm,
        \item \textbf{Palm and finger strips features}
        \begin{itemize}
          \item Eigenfingers and eigenpalm features (PCA)
          \item High recognition accuracy for some fingers (esp. middle and ring, not for thumb)
          \item Palm: >98\% recognition for >70 features. Local minutiae extraction and MCC.
          \item Quality definitions:
          Local clarity score; Ridge valley uniformity; Orientation certainty level; Orientation flow; Frequency domain analysis; Radial power spectrum; Gabor filters (several variants)
        \end{itemize}
      \end{itemize}

      \textbf{Palm Veins}:
      \begin{itemize}
        \item \textbf{Properties, sensing and imaging}
        \begin{itemize}
          \item Cross section through the skin. Thick, hairless skin
          \item Veins less numerous but more distinct in dorsal imaging than palm imaging
          \item Near-Infra-Red (NIR) sensing
          \item \textbf{Imaging}:
          \begin{itemize}
            \item Light reflection method -- Near-infrarred light (LED) reflected (in not-vein?); Image sensor (CCD cam)
            \item Light transmission method -- Near-infrarred light (LED) goes through (vein?); Image sensor (CCD cam)
          \end{itemize}
          \item Vascular patterns not apparent under visual light. Infra-red light causes veins (hemoglobin) to appear black
          \item Images depend on temperature
        \end{itemize}
        \item \textbf{Hand-vein recognition} -- Invariant, can be used together with fingerprints, can be used for left and right hands...
        \begin{itemize}
          \item \textbf{Skeletonization}: (a) Original far infrared image of the back of the hand, (b) Extraction of the region of interest, (c) Image enhancement of the region of interest, (d) Extraction of the vein lines, (e) Skeletonization of the vein lines\\ Minutiae-like approach: Cross- and end-points detection. Can be done by:
          \begin{itemize}
            \item Crossing number (counting \emph{pixel neighbors})
            \item Convolution Based Minutiae Extraction: Convolving skeleton image with a single bi-dimensional filter $G$ and two look up tables $Te$ and $Tb$ (sets of filter response values for endpoints and bifurcations, respectively)
          \end{itemize}
          \item \textbf{Principal Component Analysis (PCA)}
          \item \textbf{Linear Discriminant Analysis (LDA)} (Fisher-veins)
          \item \textbf{Radon Transform}
          \item \textbf{Complex Matched Filtering}
          \item \textbf{Local Texture Patterns}
          \begin{itemize}
            \item Local Binary Patterns (LBPs)
            \begin{itemize}
              \item Region of Interest (ROI): Find hand contour; Find reference points between fingers (determine left or right hand); Draw a square based on reference points; Re-scale to average size
              \item Pre-processing, to enhance veins. Methods: Adaptive Histogram Equalization, Morphological Background Removal, Directional Filter Enhancement
              \item Code (texture micro-pattern) computer per pixel (Gray-level difference encoded)
            \end{itemize}
            \item Local Derivative Patterns (LDPs)
          \end{itemize}
        \end{itemize}
      \end{itemize}
      \newpage
  \subsection*{Behavioral Characteristics}
    \subsubsection*{07. Voice (02, 03)}
      \begin{figure}[htp]
        \centering
          \includegraphics[width=.7\textwidth]{summaries/speak.png}
          %\caption{Sample Figure}
          %\label{fig:sample fig}
      \end{figure}
      \begin{figure}[htp]
        \centering
          \includegraphics[width=.7\textwidth]{summaries/speak2.png}
          %\caption{Sample Figure}
          %\label{fig:sample fig}
      \end{figure}
      \textbf{Generalities}:
      \begin{itemize}
        \item \textbf{Voice biometric} combines physiological and behavioral characteristics. Useful for remote-access transactions over telecommunication networks. Voice is subject to many sources of variability.
        \item \textbf{Disambiguation} -- Voice recognition can refer to \emph{Speaker recognition} (who is speaking) or \emph{Speech recognition} (what is being said).
        \item \textbf{Perceptual Cues}: \emph{High-level} (learned behaviors -- Semantic, Dialogic, Idiolectal that depend on status, education, place of birth) vs \emph{Low-level} (physical characteristics -- Spectral, Prosodic, Phonetic that depend on anatomical structure)
      \end{itemize}

      \textbf{Sensing}:
      \begin{itemize}
        \item \textbf{Microphones} (e.g. in smartphones)
        \item \textbf{Speech signal} is real, continuous, non-stationary, 4-dimensional (4D), has finite energy. It's complex and variable over time. Sometimes periodic (pseudo-periodic) for voiced sounds; Sometimes random for fricative sounds; Sometimes impulsive in explosive phases of occlusive sounds.
        \item \textbf{Bandwidth} -- Frequency Band of Telephone Speech: 300 Hz -- 3.4 kHz
        \item \textbf{Coding Bands}:
        \begin{itemize}
          \item Hi-Fi: 20 Hz -- 20 kHz (sampling frequency 44.1 kHz)
          \item Wideband: 50 Hz -- 7 kHz (sampling frequency 16 kHz)
          \item Narrow band: 300 Hz -- 3.4 kHz (sampling frequency 8 kHz)
        \end{itemize}
        \item \textbf{Sampling} and Uniform \textbf{Quantization}: \todo[inline]{}
      \end{itemize}

      \begin{figure}[htp]
        \centering
          \includegraphics[width=.85\textwidth]{spk.png}
          \caption{Enrolment and Scoring in Speaker Recognition}
          \label{fig:spk}
      \end{figure}

      \textbf{Feature extraction}: Spectral envelope, MFCC \todo[inline]{this??}
      \begin{itemize}
        \item \textbf{Mel-Frequency Cepstral Coefficients (MFCCs)}: Mel-Frequency Cepstrum (MFC) is a representation of spectral energy of a sound on the mel scale, and is made up by the MFCCs (coefficients). In an MFC the frequency bands approximates the human auditory system's response -- better representation of sound.
        \begin{itemize}
          \item GMMs are used to capture the distribution of MFCCs in the feature space.
          \item We enroll a speaker by adapting the UBM using the speaker's input.
          \item Are obtained through FFT (Short-term transform), Logarithm, Deconvolution source/tract (cepstre). The acoustic vector consists of cepstrum, delta-cepstrum and delta-delta-cepstrum
          \item \textbf{Short-Term Feature Extraction}: \todo[inline]{Window, frame, feature vector (acoustic vector)}
          \item \textbf{Short-term Processing}: \todo[inline]{window N, frame M, window and frame duration definitions}
          \item \textbf{Short-term DFT} 
          \item \textbf{Spectral envelope} \todo[inline]{(+spectrogram)}
          \item \textbf{Real Cepstrum}
          \item \textbf{Dynamic features}
        \end{itemize}
        \item Recent research on supervectors and i-vectors.
      \end{itemize}

      \textbf{Templates}:
      \begin{itemize}
        \item \textbf{Template} is a compact, electronic representation of a biometric sample that is created at the time of enrollment and stored in the system database for future reference and comparison. The process of creating a template and storing it in the database is called \emph{enrollment}.
        \item \textbf{Speech Modalities}:
        \begin{itemize}
          \item \emph{Text-dependent}: System knows text spoken (e.g. find fixed phrase, prompted phrase). Used for strong control over user input. Improved system performance.
          \item \emph{Text-independent}: Not know text spoken (e.g. conversation). Less control over user input. More flexible and more difficult.
        \end{itemize}
        \item \textbf{Vector Quantization} \todo[inline]{explain VQ}
      \end{itemize}

        \begin{table}[htp]
          \centering
          %\renewcommand{\arraystretch}{1.2}
          \begin{tabular}{lll}
          \toprule
          & \textbf{Deterministic}    & \textbf{Statistical}   \\
          \midrule
          \textbf{Text-dependent}       & Dynamic Time Warping (DTW) & Hidden Markov Model (HMM)      \\
          \textbf{Text-independent}     & Vector Quantization (VQ)   & Gaussian Mixture Model (GMM)   \\
          \bottomrule
          \end{tabular}
          \caption{\emph{Templates and Models} in Speaker Recognition}
          \label{tab:spk}
        \end{table}

      \textbf{Matching (comparison)}:
      \begin{itemize}
        \item \textbf{Comparative analysis} is a comparison between two biometrics, typically a tested sample and an enrollment (reference) template or model. The output of the comparison is a distance or score.
        \item \textbf{Speaker Recognition Systems}:
        \begin{itemize}
          \item \emph{Conventional Speaker Verification System}\\Enrollment: \\
          GMM training $\rightarrow$ Speaker-dependent GMM $\rightarrow$ Database
          \item \emph{SV with Verbal Information Verification}\\Automatic enrollment: \\
          Verbal Information Verification $\Rightarrow$ Save for training $\rightarrow$ Verified pass-phrases for training $\rightarrow$ HMM training $\rightarrow$ Speaker-dependent HMM $\rightarrow$ Database
          \item \emph{Text-prompted Speaker Recognition}: Uses \textbf{speaker-specific phoneme models} as basic acoustic units. New prompted sentence every time -- can't cheat with pre-recordings.
        \end{itemize}
        \item \textbf{Prerequisites for good performance in Speaker Recognition}: Speakers must not disguise their voices; Recording conditions and signal processing techniques are known or controlled; Speech recorded in conditions similar to those of the test signal is available; Reference values for similarity measures established in similar conditions as the test signal; Decision thresholds calibrated according to reference values depending on the application.
      \end{itemize}
    \newpage
    \subsubsection*{08. Dynamic Signature}
      \begin{figure}[htp]
        \centering
          \includegraphics[width=.7\textwidth]{summaries/sign.png}
          %\caption{Sample Figure}
          %\label{fig:sample fig}
      \end{figure}
      \textbf{Generalities}:
      \begin{itemize}
        \item \emph{Behavioral} characteristic. Combines \emph{knowledge} and \emph{biometric}. Not \emph{permanent} (invariant over time). Currently can be digitalized and is in ID cards.
        \item \textbf{Applications}: Signature forensics, Signature authentication, Signature surveillance, Digital Rights Management, Biometric cryptosystems.
        \item \textbf{Off-line} or \textbf{Static} -- scanned from paper documents, written conventionally.
        \item \textbf{On-line} or \textbf{Dynamic} -- written with electronic device. Dynamic information (pen tip location through time) usually available at high resolution, even if pen not in contact with paper.
      \end{itemize}

      \textbf{Sensing}: Multivariate sensing
      \begin{itemize}
        \item Tablets, smartphones, IKEA's and Sunrise's SignPad, UPS and SwissPost...
      \end{itemize}

      \textbf{Feature extraction}:
      \begin{itemize}
        \item \textbf{Basic (Local) Features:}
        \begin{enumerate}
          \item X, Y coordinates
          \item Velocity
          \item Acceleration
          \item Pen azimuth (0 - 359 deg)
          \item Pen altitude (0 - 90 deg)
          \item Pressure
          \item First and second derivatives of feature
        \end{enumerate}
        \item \textbf{Global features (more than 150)}
        \begin{itemize}
          \item Signature length, height, weight
          \item Total signature time
          \item Total pen-down and pen-up time
          \item Avg., max. and min. velocity
        \end{itemize}
        \item Pre-processing: Smoothing; Segmentation (determine beginning and end); Initial point alignment.
        \item Forgery: Zero-effort; Home-improved (based on static image); Over-the-shoulder (observe signing); Professional (skilled individuals). Over-the-shoulder + Home-improved combo is called \emph{skilled}.
      \end{itemize}

      \textbf{Templates}
      \begin{itemize}
        \item \emph{Models of Features for Recognition and Classification} are DTW, GMM, HMM chain with discrete distribution of observation probabilities, Continuous Density HMM (CDHMM), Viterbi algorithm for maximal probability scoring)
        \item \emph{Enrolment and Template Creation}: Baum-Welch algorithm for re-estimation of HMM chain parameters.
      \end{itemize}

      \textbf{Matching (comparison)}:
      \begin{itemize}
        \item DET curves to compare different GMMs, HMM...
        \item Resistant to imposters, non-invasive, can be changed by users, fast and intuitive enrolment, fast verification, independent of native language user.
        \item Inconsistent signatures increase error rates, limited applications, for good accuracy a 5D pen is needed (costly), some people can't sign.
      \end{itemize}
    \subsubsection*{09. Gait, Typing Rhythm}
      \textbf{Generalities}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Sensing}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Feature extraction}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Templates}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Matching (comparison)}:
      \begin{itemize}
        \item 
      \end{itemize}
  \subsection*{Biological Traces}
    \subsubsection*{10. DNA}
      \textbf{Generalities}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Sensing}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Feature extraction}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Templates}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Matching (comparison)}:
      \begin{itemize}
        \item 
      \end{itemize}
  \subsection*{Synthetic Biometric Data Generation}
    \subsubsection*{11. Synthesis of Fingerprints}
      \textbf{Synthetic Fingerprint Generation}: To automatically create large databases of fingerprints, allowing to train, test, optimize and compare algorithms. Collecting fingerprints is expensive (money and time) and problematic (privacy legislation).
      \begin{enumerate}
        \item Select  $\rightarrow$ Obtain:
        \begin{enumerate}
          \item shape parameters $\rightarrow$ \textbf{fingerprint shape}
          \item class and singularities $\rightarrow$ \textbf{directional map} model
          \item average density (and singularities) $\rightarrow$ \textbf{density map} model
        \end{enumerate}
        \item \textbf{Ridge pattern} generation, to obtain \textbf{master} fingreprint
        \begin{itemize}
          \item Gabor filters iteratively applied to an initially white image, enriched with a few random points. Orientation and frequency of the filters are locally adjusted according to directional and density maps.
          \item As a result, realistic minutiae appear at random positions.
        \end{itemize}
        \item Add \textbf{variability} data:
        \begin{enumerate}
          \item Determine contact region and erosion/dilation (low-pressure or dry/high-pressure or wet)
          \item Skin deformation
          \item Noise and rendering
          \item Translation and rotation
          \item Generate background
        \end{enumerate}
      \end{enumerate}
      \begin{figure}[htp]
        \centering
          \includegraphics[width=.45\textwidth]{fg.png}
          \caption{Synthetic Fingerprint Generation}
          \label{fig:fg}
      \end{figure}
  \newpage
  \subsection*{Multimodal Biometrics}
    \subsubsection*{12. Multimodal Biometrics}
      \textbf{Generalities}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Sensing}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Feature extraction}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Templates}:
      \begin{itemize}
        \item 
      \end{itemize}

      \textbf{Matching (comparison)}:
      \begin{itemize}
        \item 
      \end{itemize}
  \subsection*{Miscellaneous}
    \subsubsection*{13. Quality and Ageing in Classication of Biometric Data}

\newpage

\section*{Question 2 -- Other Topics} % (fold)
\label{sec:question_2_other_topics}
  \subsection*{Fundamentals of Biometrics (01)}
    \subsubsection*{01. Identity and Biometrics}
      The role of Biometrics is to recognize a person by their body traits and link the body to an externally assigned identity.

      \textbf{Biometrics}:
      \begin{itemize}
        \item \emph{Biometrics} -- automated recognition of individuals based on biological and behavioral characteristics
        \item \emph{Biometry} -- statistical and mathematical methods applicable to data analysis problems in the biological sciences
        \item \emph{Biometric system} -- automatic pattern recognition system that recognizes a person by verifying the authenticity of a specific biological and/or behavioral characteristic (biometric modality) they possess
        \item (forensic, judicial) \emph{Anthropometry} -- (identification of criminals by) measurement techniques of human body and its specific parts
      \end{itemize}
      \textbf{Identity}:
      \begin{itemize}
        \item \emph{Identity} -- whatever makes something the same or different.
        \item \emph{Authentication} (identity verification) -- process to link a physical person with a certain identity
      \end{itemize}

      People are identified by \textbf{three basic means}:
      \begin{itemize}
        \item Something they \emph{have} -- identity document or card, passport, birth certificate, token...
        \item Something they \emph{know} -- password, PIN, name, date of birth
        \item Something they \emph{are} -- human body
      \end{itemize}

      \textbf{Security level of each solution}:
      $$\text{Know} \qquad<\qquad \text{Know}+\text{Have} \qquad<\qquad \text{Know}+\text{Are} \qquad<\qquad \text{Know}+\text{Have}+\text{Are}$$

      \textbf{Advantages of Biometric identifiers}: \emph{Security}; \emph{Convenience}; \emph{Audit trial}; \emph{Avoid fraud}; \emph{De-duplication}. Examples: automated comparison process occurs in seconds; can replace passwords (often forgotten, lost, or misappropriated); identity justification without paperwork.

      \textbf{Ideal biometric identifier}: \emph{Universality} (every person has it); \emph{Uniqueness} (different for every person); \emph{Permanence} (invariant in time); \emph{Collectability} (measurable, practical); \emph{Acceptability} (public has no strong objections).

      \textbf{Challenge of biometrics}: \emph{Scalability}, \emph{Usability}, \emph{Accuracy}.

      \textbf{Identifiable biometric characteristics}: \emph{Biological traces} (DNA, blood, saliva); \emph{Biological (physiological) characteristics} (fingerprint, iris, retina, hand palm, hand veins, hand geometry, facial geometry); \emph{Behavioral characteristics} (dynamic signature, gait, keystroke dynamics, lip motion); \emph{Combined} (voice).

      \textbf{Comparison of biometric techniques} (Cost and Accuracy):
      $$\text{Cost: }\qquad\qquad\text{Voice} \quad<\quad \text{Face} \quad\approx\quad \text{Fingerprint} \quad<\quad \text{Signature} \quad<\quad \text{Hand} \quad<\quad \text{Iris}$$
      $$\text{Accuracy: }\qquad\text{Voice} \quad\approx\quad \text{Face} \quad\approx\quad \text{Signature} \quad<\quad \text{Hand} \quad<\quad \text{Fingerprint} \quad<\quad \text{Iris}$$
      \newpage
    \subsubsection*{02. Recognition, Verification, Identification and Authentication (01)}
      \textbf{Recognition} -- used when we do not distinguish between verification, identification and authentication.

      \textbf{Verification} -- performs one-to-one comparison of a submitted biometric characteristic (sample) set against a specified stored biometric reference, and returns the comparison score and decision (deciding whether a sample belongs to a specified 
      person) -- \emph{Is this person who he claims to be?}

      \textbf{Identification} -- performs one-to-many comparison/search to determine the identity of the user from a known set of identities -- \emph{Who is this person?}

      \textbf{Authentication} -- the user claims an identity and the system verifies whether the claim is genuine (link a person with a chosen identity).

      \begin{figure}[htp]
        \centering
          \includegraphics[width=\textwidth]{vfa.png}
          \caption{Enrolment, Verification and Identification}
          \label{fig:vfa}
      \end{figure}
  \subsection*{Analysis, Modeling and Interpretation of Biometric Data}
    \subsubsection*{03. Mathematical Tools: Dynamic Time Warping (DTW) (02,03)}
      \begin{itemize}
        \item In voice: Algorithm for measuring \textbf{dissimilarity} (distance) between two temporal sequences, which may vary in speed. Given a test word $T$ and reference words $R_1$, ... $R_N$ (all represented by sequences of feature vectors), we choose the reference word $R_r$ with smallest distance $D(T,R_r)$.
        \item In voice: The recognition system is adapted to the single speaker who uttered the reference word. Limited vocabulary, without words too close phonetically. The words to be recognized are pronounced in an environment free of noise. They could be isolated in a perfect manner.
        \item \textbf{Non-linear time alignment}: The sequences are \emph{warped} non-linearly in time dimension to determine a measure of their similarity independent of certain non-linear time variations.
        \item \textbf{Algorithm}. \emph{Conditions}: Boundary; monotonicity; step size.
        \begin{itemize}
          \item Recursively calculate a minimum accumulated distance for each point $(i, j)$ taking into account some local heuristic constraints and weights.
          \item Each grid point $(i,j)$ is associatied with a \emph{local distance} $d(i,j)$ and an accumulated distance $D(i,j)$.
          \begin{figure}[htp]
            \centering
            \begin{subfigure}{.32\textwidth}
              \centering
              \includegraphics[width=\textwidth]{LCA.png}
              \caption{Local constraints (A)}
              \label{fig:lca}
            \end{subfigure}%
            \hfill
            \begin{subfigure}{.32\textwidth}
              \centering
              \includegraphics[width=\textwidth]{LCB.png}
              \caption{Local constraints (B)}
              \label{fig:lcb}
            \end{subfigure}
            \hfill
            \begin{subfigure}{.29\textwidth}
              \centering
              \includegraphics[width=\textwidth]{LCC.png}
              \caption{Local constraints (C)}
              \label{fig:lcc}
            \end{subfigure}
            %\caption{Sample Figure with subfigures}
            %\label{fig:samplesubfig}
          \end{figure}
          \item Type C constraints: Allow a path of any shape satisfying monotonicity.
          \item Spectral distance: \todo[inline]{esto?}
        \end{itemize}
      \end{itemize}
    \subsubsection*{04. Mathematical Tools: Gaussian Mixture Model (GMM) (02,03)}
      \begin{itemize}
        \item A Gaussian Mixture Model (GMM) is a parametric probability density function represented as a weighted sum of Gaussian component densities.
        \item Under the assumption that any arbitrary probability density function (PDF) can be approximated by a linear combination of uni-modal Gaussian densities, the Gaussian mixture models (GMMs) have been applied to model the distribution of a sequence of D-dimensional feature vectors.
        \item The sum of \emph{mixture weights} equals 1.
        \item Model parameters: $\lambda = \{w_i, \mu_i,\Sigma_i\}$ (estimated with Expectation Maximization algorithm, although can also be estimated with Maximum A Posteriori estimation).
        \begin{itemize}
          \item Expectation step: Compute a posteriori probability for component $i$
          \item Maximization step: Maximize, guaranteeing a monotonic increase in model's likelihood.
        \end{itemize}
        \item MAP estimation is used in speaker recognition to derive speaker model by adapting from a speaker independent universal background model (UBM), or to adapt a prior, general model.
        \item Decision is carried out using a likelihood test with $H_0$ (tested recording and speaker's model are from same source), $H_1$ (not $H_0$) and Bayes theorem ($\sigma$ is the decision threshold): $$\frac{P(T|\lambda_0)}{P(T|\lambda_1)}>\sigma$$
        \item Similarity domain normalization: $\log{L(X)} = \log{p(X|S=S_c)} -
        \log{\sum_{S\in\text{Cohort}}{p(X|S \neq S_c)}}$
        \item Normalization by a general/world model: A Gaussian mixture which models the parameter distribution for free-text utterances by many speakers.
      \end{itemize}
    \newpage
    \subsubsection*{05. Mathematical Tools: Hidden Markov Model (HMM) (02,03)}
      \begin{itemize}
        \item HMM is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobserved (i.e. hidden) states. Is doubly probabilistic finite-state machine.
        \item \textbf{Ergodicity}: There is transition from any state to any other state.
        \item \textbf{Three Basic HMM Problems}:
        \begin{enumerate}
          \item \textbf{Decoding} -- Given the observation sequence $X=[x(1),x(2),...,x(t),...,x(L)]$ and the word model $W=(A,B)$, how do we choose a state sequence $Q=[q(1),q(2),...,q(t),...,q(L+1)]$ that is optimal in some meaningful sense sense (e.g. maximal probability)?
          \item \textbf{Evaluation} -- Given the observation sequence $X=[x(1),x(2),...,x(t),...,x(L)]$ and a word model $W=(A,B)$, how do we (efficiently) compute $P(X|W)$ (probability of the observation sequence)?
          \begin{itemize}
            \item The Baum-Welch algorithm (\textbf{forward}): $\alpha_j(t)=\sum_i{\alpha_i(t-1)\cdot\alpha_{ij}\cdot B_{ij}(X(t))}$
            \item The Baum-Welch algorithm (\textbf{backward}): $\beta_i(t)=\sum_j{B_{ij}(X(t+1))\cdot\alpha_{ij}\cdot\beta_{j}(t+1)}$
            \item \textbf{Total probability}: $P(X|W)=\alpha(L, q_F)=\beta(0,q|I)$
          \end{itemize}
          \item \textbf{Training} -- How do we adjust the model parameters $W=(A,B,\pi)$ to maximize $P(X|W)$?\\
          Algorithm de Baum-Welch (forward-backward):
          \begin{itemize}
            \item Calculate \emph{all forward-backward} probabilities for all states $q_i$
            \item Calculate posterior probability of transitions $\gamma_{ij}$, from state $i$ to state $j$, conditioned on the observation sequence and the model.
            \item Obtain a new estimate $a_{ij}=\gamma_{ij}(X)/\gamma_i$
            \item If the value of the total probability has not improved compared to the previous iteration, the re-estimation has converged.
          \end{itemize}
        \end{enumerate}

        \item Continuous Density HMM (CD-HMM) -- Parametric approach: Continues probability density functions (ergodic and left-right models).

        \item \emph{Viterbi Algorithm}: By induction, find the path that leads to a \emph{Max. Likelihood} considering the best likelihood at the previous step and the transitions from it.
      \end{itemize}
    \subsubsection*{06. Mathematical Tools: Principal Component Analysis (PCA) -- Karhunen-Loeve transformation}
      \begin{itemize}
        \item \emph{Seeks directions that are efficient for representing the data}, \emph{maximize determinant of total scatter} -- Find set of parameters s.t. most variability in the data is compressed in first parameters. The transformed PCA parameters are orthogonal. It diagonalizes the covariance matrix $\rightarrow$ diagonal elements are the variances of the transformed PCA parameters.
        \item Advantages and disadvantages:
        \begin{itemize}
          \item \emph{Advantages}: Completely decorrelates; packs the most variance in the fewest number of transform coefficients; minimizes MSE between reconstructed and original data; minimizes the total entropy of the data.
          \item \emph{Disadvantages}: Not fast implementation and computationally costly to get eigenvalues and eigenvectors; not a fixed transform -- needs to be generated for each type of data statistic; problems for different illumination, pose, expression.
        \end{itemize}
        \item To obtain $K$ eigenfaces:
        \begin{enumerate}
          \item Let $X_{DM}$ the matrix that has features per rows ($X_{DM}$ has been mean-centered, $X=X_0-\mu$).
          \item Compute covariance (scatter) matrix $C_{DD}=X\cdot X^T$ (or $C_{MM}=X^T\cdot X$, if $D$>>$M$)
          \item SVD: Compute eigenvectors and Eigenvalues of chosen $C$
          \item Choose $K$ largest eigenvalues
          \item Form $W_{DK}$ with $K$ columns of eigenvectors
          \item Transform data/features by projecting onto face space: $X_\text{PCA}=W^T\cdot X$
          \item Extra stuff: $E_{DD}=W^TC_{DD}W$, $E_{MM}=V^TC_{MM}V$ (both $E$ are the same, only adding 0 to get correct dimension); $X=W\cdot E\cdot V^T$
        \end{enumerate}
        \item To recognize a face $r$:
        \begin{enumerate}
          \item Subtract average face from it $r_m=r-m$
          \item Compute its projection onto the face space $x_{PCA} = W^T\cdot r_m$
          \item Compute its difference w.r.t all known faces
          \item Reconstruct the face from eigenfaces: $r_{PCA}=W\cdot x_{PCA}$
          \item Distance between the face and its reconstruction: $|r_m-r_{PCA}|_2^2$ (depending on value, $r$ can be not a face, a new face or a known face)
        \end{enumerate}
      \end{itemize}
    \subsubsection*{07. Mathematical Tools: Linear Discriminant Analysis (LDA)}
      \begin{itemize}
        \item \emph{Seeks directions that are efficient for discrimination between the data}: maximizes ratio between determinant of \emph{between-class scatter} and determinant of \emph{within-class scatter}.
        \item Problems: Small databases; the face to classify must be in database.
        \item Compute Fisherfaces:
        \begin{enumerate}
          \item Compute average of all faces ($m$)
          \item Compute average face of each person $x_i=1/2\cdot (a_i+b_i)$
          \item Substract average person face for training faces ($a_i^m$=$a_i$-$x_i$, $b_i^m$=$b_i$-$x_i$)
          \item Build \textbf{between-class scatter matrix} $S_B=\sum_i{2\cdot|x_i-m|^2_2}$
          \item Build scatter matrices $S_i=a_i^m\cdot (a_i^m)^T + b_i^m\cdot (b_i^m)^T$
          \item Build \textbf{within-class scatter matrix} $S_W=\sum_i{S_i}$
          \item We are seeking the matrix $W$ maximizing the ratio between \emph{between-class variance} and \emph{within-class variance} is maximized: $$J(W)=\frac{|W^TS_BW|}{|W^TS_WW|}$$
          \item Project faces onto LDA-space: $x_{LDA}=W^Tx$
        \end{enumerate}
        \item To classify a face:
        \begin{enumerate}
          \item Project it onto LDA space
          \item Run a nearest-neighbor classifier
        \end{enumerate}
        \item \textbf{Comparison with PCA}:
          \begin{table}[htp]
            \centering
            \renewcommand{\arraystretch}{1.2}
            \begin{tabular}{ll}
              \toprule
              \textbf{LDA} & \textbf{PCA} \\
              \midrule
              \emph{Fisherfaces}  & \emph{Eigenfaces}\\
              Discrimination & Uncorrelated representation\\
              Maximize \emph{inter} to \emph{intra} class variability & Lower dimensional space\\
              $N^2$ $\Rightarrow$ $P-1$, $P$ nb. classes & $N^2$ $\Rightarrow$ $K$\\
              Works with different illumination & Problems with different illumination \\
              Same intra-class variability for all classes      & Verify if it's a face \\
              \bottomrule
            \end{tabular}
            %\caption{Some table }
            %\label{tab:sample table}
          \end{table}
        \item \textbf{Combination of PCA and LDA} --
          First apply PCA to reduce dimensionality, then apply LDA:
          $$W_\text{Fisher}=\text{arg}\max_W{\frac{W^TW^T_\text{PCA}S_BW_\text{PCA}W}{W^TW^T_\text{PCA}S_WW_\text{PCA}W}}$$
      \end{itemize}
    \subsubsection*{08. Enrollment and Template Creation}
    \subsubsection*{09. Verification and Identification System Errors}
    \subsubsection*{10. Evaluation of Biometric Systems (01,03)}
      \textbf{Performance evaluation}:
      \begin{itemize}
        \item \textbf{Evaluation factors}: Speech quality, Speech modality, Speech duration, Speaker population.
        \item \textbf{FMR} and \textbf{FNMR}:
        \begin{itemize}
          \item False Match Rate \textbf{FMR} -- proportion of impostor attempt samples falsely declared to match the compared nonself template (number of impostor FMs / number of impostor attempts)
          \item False Non-Match Rate \textbf{FNMR} -- proportion of genuine attempt samples falsely declared not to match the template of the same characteristic from the same user submitting the sample (number of genuine FNMs / number of genuine attempts)
          \item \textbf{Calculation}: Create biometric templates using training data set. Define a test set with genuine and impostor trials. Run test and group genuine and impostor scores. Choose threshold value T and calculate FMR(T) and FNMR(T).
        \end{itemize}
        \item \textbf{FAR} and \textbf{FRR}:
        \begin{itemize}
          \item False Accept Rate \textbf{FAR} -- Proportion of imposters accepted (security breaches)\\\textbf{FAR}=FMRx(1-FTA)
          \item False Reject Rate \textbf{FRR} -- Proportion of genuine users rejected (inconvenience)\\\textbf{FRR}=FTA+FNMRx(1-FTA)
        \end{itemize}
        \item \textbf{DET} and \textbf{ROC} curves:
        \begin{itemize}
          \item Detection Error Tradeoff \textbf{DET} -- can be computed from distributions of scores with a variable threshold. FAR vs FRR
          \item Receiver Operating Characteristic \textbf{ROC} -- Correct Accept Rate as function of False Accept Rate (FAR)
        \end{itemize}
        \item \textbf{CAR} and \textbf{CRR}:
        \begin{itemize}
          \item Convenience -- Correct Accept Rate \textbf{CAR}=1-FRR
          \item Security -- Correct Reject Rate \textbf{CRR}=1-FAR
        \end{itemize}
        \item \textbf{FTA} and \textbf{FTE}:
        \begin{itemize}
          \item Failure to Acquire Rate \textbf{FTA} -- Proportion that cannot be verified (does not process a certain biometric)
          \item Failure to Enroll Rate \textbf{FTE} -- Proportion that cannot be enrolled (system fails to complete the enrolment process, due to bad quality)
        \end{itemize}
        \item \textbf{Performance measures for identification}:
        \begin{itemize}
          \item Correct Identification Rate (\textbf{CIR}) -- proportion of identification transactions by users in the system s.t. the user's identifier is among the ones returned.
          \item Cumulative Match Characteristic (\textbf{CMC}) -- Identification rate as function of K.
        \end{itemize}

      \end{itemize}
      \begin{figure}[htp]
        \centering
          \includegraphics[width=.5\textwidth]{thres.png}
          \caption{Threshold T, FRR and FAR}
          \label{fig:frrfar}
      \end{figure}
  \newpage
  \subsection*{Miscellaneous}
    \subsubsection*{11. Forensic Automatic Speaker Recognition (03)}
      \begin{figure}[htp]
        \centering
          \includegraphics[width=.7\textwidth]{summaries/fasr.png}
          %\caption{Sample Figure}
          %\label{fig:sample fig}
      \end{figure}
      \begin{itemize}
        \item \textbf{Forensic Biometrics} -- Challenge is to automate forensic biometric methods. Applications of biometric principles and methods to the investigation of criminal activities: to demonstrate the existence of a crime and determine the author. \emph{Forensic} means the use of science or technology in the investigation and establishment of facts or evidence in the court of law.
        \item \textbf{Existing systems and databases}:
        \begin{itemize}
          \item Automatic Fingerprint Identification System (AFIS) and fingerprints databases
          \item DNA sequencers and DNA databases
          \item Challenge: Automatic Biometric Identification System (ABIS) and databases for voice, face...
        \end{itemize}
        \item \textbf{Speaker Identification Integrated Project (SIIP)} -- Aims to develop technology to rapidly identify suspects' voices and isolate conversations of interest in a wide range of cases (kidnapping, ransom or terrorist calls...)
        \item \textbf{Forensic Speaker Recognition (FSR)}:
        \begin{itemize}
          \item \textbf{Aural-perceptual methods}: earwitnesses, line-ups
          \item \textbf{Visual methods and \emph{voiceprint?}}: visual comparison of spectrograms of linguistically identical utterances (utterly misleading!)
          \item \textbf{Aural-instrumental methods}: analytical acoustic approach combined with an auditory phonetic analysis
          \item \textbf{Automatic methods}:
          \begin{itemize}
            \item \emph{Speaker verification} -- not adequate
            \item \emph{Speaker identification} -- not adequate
            \item \emph{Voice as biometric evidence} (How to measure biometric evidence?)
          \end{itemize}
        \end{itemize}
        \item \textbf{Automatic Speaker Recognition (ASR)}:
        \begin{itemize}
          \item FASR $\neq$ Speaker Verification
          \item $H_0$ ($H_1$) -- speaker's model $\lambda_0$ and the tested recording $T$ have same (different) source.
          $$\frac{P(H_0)}{P(H_1)}\cdot\frac{P(T|H_0)}{P(T|H_1)}=\frac{P(H_0|T)}{P(H_1|T)}\qquad\qquad\frac{P(T|\lambda_0)}{P(T|\lambda_1)}>\sigma\qquad\text{($\sigma$ -- Decision threshold)}$$
        \end{itemize}
        \item See Table \ref{tab:spk}.
        \item \textbf{Forensic Automatic Speaker Recognition (FASR)}:
        \begin{itemize}
          \item \textbf{Forensic specifity} -- Role of \emph{forensic science} is to testify to the worth of the evidence \emph{quantitatively} (if possible). Forensic science provides \emph{opinion} to help investigators and courts of law answer important questions. Up to the \emph{judge/jury} to use this information in deliberations and decision.
          \item \textbf{Evaluative forensic science opinion} -- opinion of evidential weight, based upon case specific propositions (hypotheses) and clear conditioning information (framework of circumstances) that is provided for use as evidence in court. Is based upon the estimation of a likelihood ratio (in relation with Bayesian interpretation of evidence).
        \end{itemize}
        \item \textbf{Bayesian Interpretation of Biometric Evidence} ($H_0$ $\equiv$ suspected speaker is source of the recording). Via Bayes Rule, we use the data to update prior beliefs about unknowns. See Figure \ref{fig:byfs}. Freedom of: choosing evidence evaluation and its value; formulating propositions; choosing automatic speaker recognition method.
          \begin{figure}[htp]
            \centering
              \includegraphics[width=.7\textwidth]{byfs.png}
              \caption{Odds form of Bayes' Theorem: Bayesian Interpretation of Forensic Evidence}
              \label{fig:byfs}
          \end{figure}
        \item \textbf{Measures}:
        \begin{enumerate}
          \item \textbf{Biometric Evidence} -- Quantified degree of \emph{similarity} between the speaker dependent features extracted from the trace and the extracted from recorded speech of a suspect (model).
          \begin{itemize}
            \item \textbf{FASR -- Univariate (Scoring) Method} -- See Figure \ref{fig:spk}. The \emph{score} is used together with the distributions of \emph{between-sources variability} and the \emph{within-source variability} to reach a decision.
          \end{itemize}
          \item \textbf{Strength of Evidence -- Likelihood Ratio} -- A likelihood ratio $LR=P(E|H_0)/P(E|H_1)$ of 9.16 means that it is 9.16 times more likely to observe the score (E) given $H_0$ than given $H_1$. If $LR>1$ then $H_0$, else $H_1$.
          \begin{itemize}
            \item \textbf{FASR -- Multivariate (direct) Method} -- E is the multivariate feature representation of trace evidence.
          \end{itemize}
          \item \textbf{Evaluation of the Strength of Evidence} -- (similar idea to Figure \ref{fig:frrfar}) \emph{Principle}: Estimation and comparison of likelihood ratios that can be obtained from same speaker and different speaker trials. $H_0$ true $\rightarrow$suspected person recording and questioned recording are from same speaker.
          \begin{itemize}
            \item Tippett plots I to obtain \emph{Probability of Misleading Evidence (accuracy)} $\text{PME}H_0$ and $\text{PME}H_1$.
            \item Tippett plots II to obtain EPP (Equal Proportion Probability), PD (Probabilistic Distance) of case $LR_{case}$ to $\text{PME}H_0$.
            \item Empirical Cross-Entropy (ECE) and Log-Likelihood Cost (CLLR) \todo[inline]{these two?}
          \end{itemize}
        \end{enumerate}
      \end{itemize}
    \subsubsection*{12. Forensic Biometrics (Fingerprints, Face, DNA, Ear, Gait)}
      \begin{itemize}
        \item \textbf{Fingerprints}: $$LR = \frac{p(\text{evidence}|H_p)}{p(\text{evidence}|H_d)}$$
        with $H_p$ (suspect left the fingerprint), $H_d$ (someone else left the fingerprint), numerator (variability of minutiae configurations due to distortion and clarity), denominator (variability between minutiae from different sources). Delaunay triangulation, MCC and Local Quality Measures (embedding quality measures), ridge quality maps are used.
        \item \textbf{Face}:
        \begin{itemize}
          \item Challenges: Forensic Sketch Recognition, Facial Aging, Facial Marks, Unconstrained Facial recognition
          \item De-identification: Blurring, pixelation
          \item Near infra-red to Visible Light images
        \end{itemize}
      \end{itemize}
    \subsubsection*{13. Biometric Standards}
    \subsubsection*{14. Securing Biometric Data and Biometric Encryption}
    \subsubsection*{15. Biometrics in Identity Documents}
    \subsubsection*{16. Privacy and Legal Issues}

\end{document}





\section{Sample Section} % (fold)
\label{sec:sample_section}

\subsection{Sample figures} % (fold)
\label{sub:sample_figures}

% subsection sample_figures (end)

\begin{figure}[htp]
  \centering
    % \includegraphics[width=\textwidth]{images/figure.pdf}
    \missingfigure[figwidth=\textwidth]{Some Figure}
    \caption{Sample Figure}
    \label{fig:sample fig}
\end{figure}

\begin{figure}[htp]
  \centering
  \begin{subfigure}{.45\textwidth}
    \centering
    \caption{First Subfigure}
    % \includegraphics[width=\textwidth]{images/figure.pdf}
    \missingfigure[figwidth=\textwidth]{Some subfigure}
    \label{fig:samplesubfiga}
  \end{subfigure}%
  \hfill
  \begin{subfigure}{.45\textwidth}
    \centering
    \caption{Second Subfigure}
    % \includegraphics[width=\textwidth]{images/figure.pdf}
    \missingfigure[figwidth=\textwidth]{Some subfigure}
    \label{fig:samplesubfigb}
  \end{subfigure}
  \caption{Sample Figure with subfigures}
  \label{fig:samplesubfig}
\end{figure}

\subsection{Sample Tables} % (fold)
\label{sub:sample_tables}

\begin{table}[htp]
  \centering
  \renewcommand{\arraystretch}{1.2}
  \begin{tabular}{llr}
    \toprule
    \multicolumn{2}{c}{Item} & \multirow{2}{*}{Price (\$)} \\
    \cmidrule(r){1-2}
    Animal    & Description &   \\
    \midrule
    \multirow{2}{*}{Gnat}      & per gram    & 13.65      \\
              &    each     & 0.01       \\
    Gnu       & stuffed     & 92.50      \\
    Emu       & stuffed     & 33.33      \\
    Armadillo & frozen      & 8.99       \\
    \bottomrule
  \end{tabular}
  \caption{Some table }
  \label{tab:sample table}
\end{table}


\begin{table}[htp]
    \centering
    \begin{subtable}[htp]{0.5\textwidth}
        \centering
        \begin{tabular}{lll}
        \toprule[1.5pt]
        \textbf{Command} & \textbf{Declaration} & \textbf{Output}\\
        \midrule
        \verb|\textnormal| &\verb|\normalfont| & Example text\\
        \verb|\textrm| & \verb|\rmfamily| & \rmfamily Example text\\
        \verb|\textsf| & \verb|\sffamily| & \sffamily Example text\\
        \verb|\texttt| &\verb|\ttfamily| & \ttfamily Example text\\
        \verb|\textit| &\verb|\itshape| & \itshape Example text\\
        \verb|\textsl| &\verb|\slshape| & \slshape Example text\\
        \verb|\textsc| &\verb|\scshape| & \scshape Example text\\
        \verb|\textbf| &\verb|\bfseries| & \bfseries Example text\\
        \verb|\textmd| &\verb|\mdseries| & \mdseries Example text\\
        % \verb|\textlf| &\verb|\lfseries| & \lfseries Example text\\
        \bottomrule[1.5pt]
        \end{tabular}
      \caption{First Subtable}
      \label{tab:subtable-a}
    \end{subtable}
    
    \begin{subtable}[htp]{\textwidth}
        \centering
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{lrrrc}
        \toprule[1.5pt]
        \textbf{Command} & \textbf{Declaration} & \textbf{Output}\\
        \midrule
        Command       & [10pt]  & [11pt]  & [12pt]  & Sample \\
        \verb|\tiny|         &  5      &  6      &  6      & {\tiny Example Text} \\
        \verb|\scriptsize|   &  7      &  8      &  8      & {\scriptsize Example Text} \\
        \verb|\footnotesize| &  8      &  9      &  10     & {\footnotesize Example Text} \\
        \verb|\small|        &  9      &  10     &  10.95  & {\small Example Text} \\
        \verb|\normalsize|   &  10     &  10.95  &  12     & {\normalsize Example Text} \\
        \verb|\large|        &  12     &  12     &  14.4   & {\large Example Text} \\
        \verb|\Large|        &  14.4   &  14.4   &  17.28  & {\Large Example Text} \\
        \verb|\LARGE|        &  17.28  &  17.28  &  20.74  & {\LARGE Example Text} \\
        \verb|\huge|         &  20.74  &  20.74  &  24.88  & {\huge Example Text} \\
        \verb|\Huge|         &  24.88  &  24.88  &  24.88  & {\Huge Example Text} \\
        \bottomrule[1.5pt]
        \end{tabular}
        \caption{Second Subtable}
        \label{tab:subtable-b}
    \end{subtable}
      \caption{Sample Subtables}
      \label{tab:subtable}
\end{table}

% subsection sample_tables (end)

\end{document}
